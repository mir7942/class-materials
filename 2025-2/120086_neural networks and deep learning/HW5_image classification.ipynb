{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"gpuType":"T4","authorship_tag":"ABX9TyMrGXeAOYxFLKCGL3fW9X5F"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["수정일: 2024.02.14"],"metadata":{"id":"xVh0GzsGeFaL"}},{"cell_type":"markdown","metadata":{"id":"0NvJ_mnDvy4P"},"source":["# HW5: Image Classification\n","\n","이번 과제에서는 CNN을 이용해 CIFAR-10 데이터셋의 이미지를 분류해 보겠다. 모델 정의를 제외한 전반 적인 과정은 이전 과제와 유사하다.\n","\n","**이번 과제에서는 GPU를 이용한다. 이를 위해서는 메뉴의 [런타임]-[런타임 유형 변경]에서 '하드웨어 가속기'를 'T4 GPU'로 선택해야 한다.**\n","\n","우선 필요한 모듈을 불러오고, 필요한 셋팅을 한다."]},{"cell_type":"code","metadata":{"id":"ONkJs3T49P4X"},"source":["import numpy as np # NumPy\n","import matplotlib.pyplot as plt # Matplotlib\n","\n","import torch # PyTorch\n","import torchvision # 데이터셋을 읽기 위해 필요\n","import torchvision.transforms as transforms # 데이터셋을 읽기 위해 필요\n","from torch import nn # PyTorch 레이어"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cMrbltOi9Tho"},"source":["## CIFAR-10 데이터셋\n","\n","[CIFAR-10 데이터셋](https://www.cs.toronto.edu/~kriz/cifar.html)은 60,000개의 컬러 이미지로 구성된 데이터셋이다. 각각의 이미지는 32x32 크기의 3채널로 구성되어 있다. 그리고, 이미지는 10개의 클래스로 분류되며, 각 클래스 당 6,000개의 이미지로 구성된다. 이 중, training set은 50,000개이며 test set은 10,000개이다. 그러나, validation을 위해 training set 중 10,000개를 이용할 것이다.\n","\n","아래 코드는 인터넷에서 CIFAR-10 데이터셋을 다운로드 받아 저장한다. 이는 [torchvision.datasets.CIFAR10](https://pytorch.org/vision/stable/datasets.html#cifar)를 이용하면 쉽게 할 수 있다. Validation set을 분리하는 것은 [torch.utils.data.dataset.random_split](https://pytorch.org/docs/stable/data.html?highlight=random_split#torch.utils.data.random_split)을 이용한다."]},{"cell_type":"code","metadata":{"id":"_gFj9FM9_DbD"},"source":["transform = transforms.Compose([transforms.ToTensor()]) # 불러온 이미지를 tensor로 변환해준다.\n","\n","dataset = torchvision.datasets.CIFAR10('dataset', train=True, download=True, transform=transform) # training set을 다운로드 한다.\n","testset = torchvision.datasets.CIFAR10('dataset', train=False, download=True, transform=transform) # test set을 다운로드 한다.\n","\n","trainset, validationset = torch.utils.data.dataset.random_split(dataset, [40000, 10000]) # training set을 다시 40000개와 10000개로 분할한다.\n","\n","# 각 클래스에 대한 이름을 저장한 배열을 만든다.\n","classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C5nk1f55_xZn"},"source":["CIFAR-10 데이터셋의 기본 정보를 출력한다. 이 때, 이미지의 크기가 32x32x3인 것을 확인하고, 각 픽셀의 값이 0에서 1 사이의 값을 갖는 것을 확인한다. 그리고, 레이블 정보는 0~9 사이의 정수로 저장되어 있다.\n","\n","**PyTorch는 이미지를 처리할 때 (채널, 세로, 가로) 순서로 데이터를 표현한다. 수업 시간에는 (가로, 세로, 채널) 순서로 표현했다는 점에 주의해야 한다.**"]},{"cell_type":"code","metadata":{"id":"OmBfUgEsAgBJ"},"source":["print(\"Traning set 개수:\", len(trainset)) # 40,000개\n","print(\"Validation set 개수:\", len(validationset)) # 10,000개\n","print(\"Test set 개수:\", len(testset)) # 10,000개\n","\n","# trainset의 데이터를 가져온다. 이 때, x에는 입력 데이터(즉, 숫자 이미지)가, y에는 입력 데이터에 대한 출력 데이터(즉, 레이블)이 저장된다.\n","for x, y in trainset:\n","  print(\"Shape of x:\", x.shape) # [3, 32, 32] (채널수, 세로 크기, 가로 크기)\n","  print(\"x:\", x) # 각 픽셀이 0~1 사이의 값을 갖는 것을 확인\n","  print(\"Label:\", y) # 0~9 사이의 값\n","  print(\"Class:\", classes[y]) # 레이블에 해당하는 클래스 이름\n","  break # 한 개에 대해서만 출력하고 종료"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Sug-I19Ffyn"},"source":["CIFAR-10 데이터셋의 일부 이미지를 출력해본다.\n","\n","PyTorch는 이미지를 (채널, 세로, 가로) 순서로 표현하지만, MatplotLib나 다른 이미지 처리 라이브러리들은 (가로, 세로, 채널) 순서로 표현하는 경우가 많다. 여기서도 이미지를 MatplotLib로 가시화하기 위해서는 (가로, 세로, 채널) 순서로 변환해 줘야 한다."]},{"cell_type":"code","metadata":{"id":"46ZjzI4pAi-_"},"source":["_, axes = plt.subplots(3, 3)\n","\n","for i, (x, y) in enumerate(trainset):\n","  img = np.transpose(x, (1, 2, 0)) # (채널, 세로, 가로) 형태를 (가로, 세로, 채널)로 변환\n","\n","  row = i // 3\n","  col = i % 3\n","  ax = axes[row, col]\n","\n","  ax.imshow(img, interpolation='none') # 이미지를 표시한다.\n","  ax.set_title(\"Ground Truth:\" + classes[y])\n","  ax.set_xticks([])\n","  ax.set_yticks([])\n","\n","  if i >= 8: # 9개의 이미지만 보여준다.\n","    break\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F9FGVI_iE6DI"},"source":["## 모델 정의\n","\n","CIFAR-10 데이터셋을 분류하기 위한 CNN 모델을 정의한다.\n","\n","지난 과제에서와 같이 CNN 모델을 정의하기 위해 [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)에서 상속받은 클래스를 정의한다. 그리고 *\\_\\_init\\_\\_()* 함수 안에 네트워크의 레이어들을 정의하고, *forward()* 함수 안에서 정의한 레이어들을 연결해 준다.\n","\n","Convolution 레이어는 [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)를 이용한다. 활성화 함수는 [nn.ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html)를 이용한다. 그리고 Max Pooling 레이어는 [nn.MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html)를 이용한다.\n","\n","추가적으로 overfitting을 줄이기 위해 dropout 레이어([nn.Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html))를 추가해본다. 이 때, dropout rate은 hyperparameter이다.\n","\n","이번 과제에서는 좋은 성능을 가지도록 **여러분이 직접 레이어를 정의**한다. 레이어는 다음과 같은 형태로 구성해야 한다.\n","\n","Conv2d -> ReLU -> MaxPool2d -> Dropout -> Conv2d -> ReLU -> MaxPool2d -> Dropout -> Conv2d -> ... -> MaxPool2d -> Dropout ->  Flatten -> Linear -> ReLU -> -> Dropout Linear -> ReLU -> ... -> Linear\n","\n","위에서와 같이 마지막 레이어는 nn.Linear가 되어야 한다. (Dropout을 추가하지 않는다.)\n","\n","**지시: 좋은 성능을 낼 수 있게 다음 CNN 모델을 정의한다.**"]},{"cell_type":"code","metadata":{"id":"-D8J2RgsGHsV"},"source":["class Cifar10Model(nn.Module): # nn.Module을 상속받은 클래스를 정의. 이름을 Cifar10Model로 정의하였다.\n","  def __init__(self): # 이 안에 레이어들을 정의한다.\n","    super(Cifar10Model, self).__init__()\n","\n","    ## 아래 코드를 적절히 수정하시오.\n","    #### 코드 시작 ####\n","    self.conv_layer = nn.Sequential(\n","      nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n","      nn.ReLU(),\n","      nn.MaxPool2d(kernel_size=2, stride=2),\n","      nn.Dropout(p=0.5)\n","    )\n","\n","    self.flatten = nn.Flatten()\n","    self.linear = nn.Linear(8192, 10)\n","    #### 코드 종료 ####\n","\n","  def forward(self, x): # 이 안에 레이어들을 연결해준다.\n","    ## 아래 코드를 적절히 수정하시오.\n","    #### 코드 시작 ####\n","    x = self.conv_layer(x)\n","    x = self.flatten(x)\n","    x = self.linear(x)\n","    #### 코드 종료 ####\n","    return x\n","\n","model = Cifar10Model().cuda() # GPU에 모델 생성"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qppXguqzLJSv"},"source":["## 학습\n","\n","학습을 위해 하이퍼파라미터를 설정한다. 이번 과제에서는 여러분이 직접 하이퍼파라미터를 설정한다.\n","\n","**지시: 좋은 성능을 낼 수 있게 아래 hyperparameter를 조정한다.**"]},{"cell_type":"code","metadata":{"id":"7D21XzI8LcQF"},"source":["# Hyperparameter를 설정한다.\n","# 사용자가 변경할 수 있다.\n","epochs = 1 # 최대 epoch\n","learning_rate = 0.1 # Learning rate\n","batch_size = 32 # Batch size"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UWlMvygZLp3m"},"source":["데이터를 batch size 단위로 나누어 불러올 수 있게 [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)를 사용한다. Training set과 validation set 모두에 대해 각각의 DataLoader를 만들어준다."]},{"cell_type":"code","metadata":{"id":"P_IorvpWMTSk"},"source":["# shuffle=True는 데이터를 불러올 때, 데이터를 섞어준다.\n","trainset_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True)\n","validationset_loader = torch.utils.data.DataLoader(dataset=validationset, batch_size=batch_size, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AUfXJXtGM-jP"},"source":["Optimizer를 정의한다. 여기서는 [Adam](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam) 알고리즘을 이용해 batch size 단위로 최적화를 한다."]},{"cell_type":"code","metadata":{"id":"2B-UJyJoNJKl"},"source":["optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tRLoUpivO678"},"source":["Loss function을 정의한다. 여기서는 PyTorch가 제공하는 [nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)를 사용한다. 이는 자체적으로 softmax 함수를 포함하므로, 모델에 softmax 활성화 함수를 별도로 추가할 필요가 없다. 또한, y를 one-hot encoding으로 변환하지 않아도 내부적으로 변환해 처리해 준다."]},{"cell_type":"code","metadata":{"id":"1g1_JrY3PC2-"},"source":["loss_function = nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PdPrCv0j3RxK"},"source":["한 번의 epoch에 대해 데이터를 batch size 단위로 모델을 학습시키는 함수를 만든다. 이 함수는 dataloader에서 batch size 만큼 데이터를 가져와 optimizer를 이용해 학습한다.\n","\n","**아래 코드에서 model.train()을 호출하는 부분을 주의깊게 보도록 한다.**"]},{"cell_type":"code","metadata":{"id":"SzVOpW7gSBzb"},"source":["def train_loop(dataloader, model, loss_func, optimizer):\n","  size = len(dataloader.dataset) # 데이터 개수\n","  training_loss = 0 # Loss를 저장하기 위한 변수\n","  correct = 0 # 정답을 맞춘한 개수를 저장\n","\n","  model.train() # 학습한다는 것을 표시함. 이는 dropout, batch normalization과 같이 학습과 평가 시 적용이 다르게 되는 레이에어 영향을 준다.\n","\n","  for X, y in dataloader: # dataloader를 이용해 batch size 만큼 입력 데이터 X와 출력 데이터 y를 가져온다.\n","    X = X.cuda() # X를 GPU로 이동\n","    y = y.cuda() # y를 GPU로 이동\n","\n","    optimizer.zero_grad() # Gradient를 0으로 초기화\n","    output = model(X) # 모델을 이용해 forward propagation 수행\n","    loss = loss_func(output, y) # loss 계산. y를 one-hot encoding으로 변환하지 않아도 된다.\n","    loss.backward() # Backpropagation 수행\n","    optimizer.step() # 가중치 업데이트\n","\n","    training_loss += loss.item() * output.shape[0] # Loss를 누적시킨다. 이 때, loss는 batch size에 대한 평균이므로 다시 곱해준다.\n","\n","    prediction = output.argmax(1) # 예측한 결과\n","    correct += (prediction == y).type(torch.float).sum().item() # 예측한 결과와 출력 데이터(정답)을 비교해 맞은 개수를 찾는다.\n","\n","  training_loss /= size # 평균 loss를 계산\n","  accuracy = correct / size # 정확도를 계산\n","\n","  return training_loss, accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uKvfQ_4G4DUM"},"source":["한 번의 epoch에 대해 데이터를 batch size 단위로 모델을 평가하는 함수를 만든다. 이 함수는 dataloader에서 batch size 만큼 데이터를 가져와 학습된 모델을 이용해 loss 및 정확도를 계산한다.\n","\n","**아래 코드에서 model.eval()을 호출하는 부분을 주의깊게 보도록 한다.**"]},{"cell_type":"code","metadata":{"id":"RyGTac5n4CmB"},"source":["def test_loop(dataloader, model, loss_func):\n","  size = len(dataloader.dataset) # 데이터 개수\n","  test_loss = 0 # Loss를 저장하기 위한 변수\n","  correct = 0 # 정답을 맞춘 개수를 저장\n","\n","  model.eval() # 평가한다는 것을 표시함. 이는 dropout, batch normalization과 같이 학습과 평가 시 적용이 다르게 되는 레이에어 영향을 준다.\n","\n","  with torch.no_grad(): # 미분을 수행하지 않음\n","    for X, y in dataloader: # dataloader를 이용해 batch size 만큼 입력 데이터 X와 출력 데이터 y를 가져온다.\n","      X = X.cuda() # X를 GPU로 이동\n","      y = y.cuda() # y를 GPU로 이동\n","\n","      output = model(X) # 모델을 이용해 forward propagation 수행하여 결과 예측\n","      loss = loss_func(output, y)\n","      test_loss += loss.item() * output.shape[0] # loss 계산. y를 one-hot encoding으로 변환하지 않아도 된다.\n","\n","      prediction = output.argmax(1) # 예측한 결과\n","      correct += (prediction == y).type(torch.float).sum().item() # 예측한 결과와 출력 데이터(정답)을 비교해 맞은 개수를 찾는다.\n","\n","    test_loss /= size # 평균 loss를 계산\n","    accuracy = correct / size # 정확도를 계산\n","\n","  return test_loss, accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3mCXWodT47Rr"},"source":["Training set을 이용해 모델을 학습하고, validation set을 이용해 검증하는 루프를 구현한다. 그리고, 매 epoch 마다 loss 및 accuracy를 저장한다."]},{"cell_type":"code","metadata":{"id":"FXCfPL1JNcCt"},"source":["# 학습 상황을 저장하기 위한 변수\n","train_loss_history = []\n","train_accuracy_history = []\n","validation_loss_history = []\n","validation_accuracy_history = []\n","\n","for epoch in range(1, epochs+1): # 최대 epoch만큼 반복한다.\n","  print(\"Epoch: \", epoch)\n","\n","  train_loss, train_accuracy = train_loop(trainset_loader, model, loss_function, optimizer) # train set을 이용해 학습한다.\n","  train_loss_history.append(train_loss) # train set에 대한 loss를 저장한다.\n","  train_accuracy_history.append(train_accuracy) # train set에 대한 accuracy를 저장한다.\n","\n","  validation_loss, validation_accuracy = test_loop(validationset_loader, model, loss_function) # validation set을 이용해 검증한다.\n","  validation_loss_history.append(validation_loss) # validation set에 대한 loss를 저장한다.\n","  validation_accuracy_history.append(validation_accuracy) # validation set에 대한 accuracy를 저장한다.\n","\n","  print(f\"Training accuracy: {train_accuracy}, Training loss: {train_loss}\")\n","  print(f\"Validation accuracy: {validation_accuracy}, Validation loss: {validation_loss}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ww4mX1uKYQQD"},"source":["매 epoch 마다 loss와 accuracy가 변하는 과정을 그래프로 보여준다. Epoch이 진행됨에 따라서 loss는 감소하고 accuracy는 증가한다. 그리고 validation loss는 test loss보다 일반적으로 크다."]},{"cell_type":"code","metadata":{"id":"kwiA3o6k5fWK"},"source":["x = np.arange(1, len(train_loss_history)+1, dtype=int)\n","\n","# Loss 그래프\n","_, ax = plt.subplots()\n","ax.plot(x, train_loss_history, label=\"training\")\n","ax.plot(x, validation_loss_history, label=\"validation\")\n","ax.set_title('Loss')\n","ax.set_xlabel('Epoch')\n","ax.set_ylabel('Loss')\n","ax.legend()\n","plt.show()\n","\n","# Accuracy 그래프\n","_, ax = plt.subplots()\n","ax.plot(x, train_accuracy_history, label=\"training\")\n","ax.plot(x, validation_accuracy_history, label=\"validation\")\n","ax.set_title('Accuracy')\n","ax.set_xlabel('Epoch')\n","ax.set_ylabel('Accuracy')\n","ax.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UHDjS8iy59Dq"},"source":["## 평가\n","평가에는 test set을 이용한다. 이를 batch size 단위로 불러오기 위해 dataloader를 만든다. 그러나 학습이 아니기 때문에 batch size 단위로 평가할 필요는 없다. 단지, 한 번에 메모리로 불러오는 부담을 줄이기 위해서이다.\n","\n","**지시: Test accuracy가 70%가 넘도록 모델 및 하이퍼파라미터를 설정한다.**"]},{"cell_type":"code","metadata":{"id":"zYOcMZ-o8PHr"},"source":["model.cuda()\n","\n","testset_loader = torch.utils.data.DataLoader(dataset=testset, batch_size=batch_size, shuffle=False)\n","test_loss, test_accuracy = test_loop(testset_loader, model, loss_function) # test set을 이용해 평가한다.\n","\n","print(f\"Test accuracy: {test_accuracy}, Test loss: {test_loss}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IGcH7ty2gk0Q"},"source":["Test set에 있는 일부 이미지 중, 임의로 몇 개 선택해서 예측이 잘 되는지 확인해 본다. 정확도가 높지 않기 때문에, 만족할 만한 결과를 보여주지는 않는다."]},{"cell_type":"code","metadata":{"id":"NCpFTHT9gtFx"},"source":["from torch.utils.data import RandomSampler\n","\n","model.cpu()\n","\n","_, axes = plt.subplots(3, 3)\n","\n","for i in range(0, 9):\n","  random_index = int(np.random.random()*len(testset))\n","  x, y = dataset[random_index]\n","\n","  img = np.transpose(x, (1, 2, 0)) # (채널, 세로, 가로) 형태를 (가로, 세로, 채널)로 변환\n","\n","  x = np.reshape(x, (1, 3, 32, 32))\n","\n","  model.eval()\n","  with torch.no_grad(): # 미분을 수행하지 않음\n","    output = model(x)\n","\n","  predicted = torch.argmax(output)\n","\n","  row = i // 3\n","  col = i % 3\n","  ax = axes[row, col]\n","\n","  ax.imshow(img, interpolation='none') # 이미지를 표시한다.\n","  ax.set_title(f\"Predicted: {classes[predicted]}\")\n","  ax.set_xticks([])\n","  ax.set_yticks([])\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w8wXW3adIo3I"},"source":["이번 과제는 여기까지 입니다. 수고하셨습니다."]}]}